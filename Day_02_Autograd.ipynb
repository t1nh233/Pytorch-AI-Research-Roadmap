{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPOq5OLFgyNHO4OrzLtYArt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/t1nh233/Pytorch-AI-Research-Roadmap/blob/main/Day_02_Autograd.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8P7jFH6eWghm",
        "outputId": "662ed8ed-6b7f-47bf-c82f-e62f8ad25ce8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "‚úÖ ƒê√£ b·∫≠t GPU: Tesla T4\n",
            "üöÄ M√¥i tr∆∞·ªùng ƒë√£ s·∫µn s√†ng!\n"
          ]
        }
      ],
      "source": [
        "# --- STARTUP BLOCK ---\n",
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "# 1. K·∫øt n·ªëi Google Drive (ƒê·ªÉ l·∫•y d·ªØ li·ªáu)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 2. T·∫°o ƒë∆∞·ªùng d·∫´n t·∫Øt (ƒê·ªÉ code cho g·ªçn)\n",
        "# L∆∞u √Ω: S·ª≠a l·∫°i ƒë√∫ng t√™n th∆∞ m·ª•c b·∫°n t·∫°o ·ªü B∆∞·ªõc 2 ph·∫ßn tr√™n\n",
        "DATA_PATH = '/content/drive/MyDrive/Pytorch_AI_Research_Bootcamp/datasets'\n",
        "MODEL_PATH = '/content/drive/MyDrive/Pytorch_AI_Research_Bootcamp/checkpoints'\n",
        "\n",
        "# 3. Ki·ªÉm tra GPU\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"‚úÖ ƒê√£ b·∫≠t GPU: {torch.cuda.get_device_name(0)}\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è C·∫£nh b√°o: B·∫°n ƒëang ch·∫°y b·∫±ng CPU. H√£y v√†o Runtime -> Change runtime type -> T4 GPU\")\n",
        "\n",
        "# 4. T·∫°o th∆∞ m·ª•c n·∫øu ch∆∞a c√≥ (Tr√°nh l·ªói)\n",
        "os.makedirs(DATA_PATH, exist_ok=True)\n",
        "os.makedirs(MODEL_PATH, exist_ok=True)\n",
        "\n",
        "print(\"üöÄ M√¥i tr∆∞·ªùng ƒë√£ s·∫µn s√†ng!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([2.0, 3.0], requires_grad=True)\n",
        "y = x**2 + 3*x + 1\n",
        "z = y.sum()\n",
        "print(y)\n",
        "print(z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "haQh20OwW5ZK",
        "outputId": "6bfaff21-b47b-49ec-a057-b7b1e6c147fb"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([11., 19.], grad_fn=<AddBackward0>)\n",
            "tensor(30., grad_fn=<SumBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Goi backward\n",
        "\n",
        "z.backward(retain_graph=True)\n",
        "print(x.grad)\n",
        "z.backward()\n",
        "print(x.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LX71j035X0oj",
        "outputId": "5919d4e3-32e8-4c0d-9ac7-10023577979e"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([7., 9.])\n",
            "tensor([14., 18.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Vay neu toi boc tat ca trong no_grad() thi sao\n",
        "\n",
        "with torch.no_grad():\n",
        "  k = x**2 + 3*x + 1\n",
        "\n",
        "print(y.grad_fn)\n",
        "print(k.requires_grad)\n",
        "print(k.grad_fn)\n",
        "print(y.grad_fn.next_functions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tyiy14OGaOtx",
        "outputId": "507b464c-559f-4b2f-c399-599e27495585"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<AddBackward0 object at 0x7afcd0d850c0>\n",
            "False\n",
            "None\n",
            "((<AddBackward0 object at 0x7afcd0c184f0>, 0), (None, 0))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MJp7KtfebhO5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}